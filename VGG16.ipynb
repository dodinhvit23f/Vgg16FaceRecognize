{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1vx4577GzuEWz3NvMBOGTgckCgu4LprCd","authorship_tag":"ABX9TyM9VqPFrIf/uxb2aeGIgwcs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OpVlCrGJn-4Q","executionInfo":{"status":"ok","timestamp":1621099106831,"user_tz":-420,"elapsed":30925,"user":{"displayName":"tien dodinhtn123","photoUrl":"","userId":"17480689431746127203"}},"outputId":"0c902ee5-74cd-4a2d-8847-3f8506371668"},"source":["pip uninstall tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"42w7Udmqgy7G"},"source":["# Mục mới"]},{"cell_type":"code","metadata":{"id":"cTJ0TcFdOjRA"},"source":["pip install tensorflow-gpu==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FK4mCfORfTxt"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXIk4Vqvg6iD","executionInfo":{"status":"ok","timestamp":1621100115638,"user_tz":-420,"elapsed":5636,"user":{"displayName":"tien dodinhtn123","photoUrl":"","userId":"17480689431746127203"}},"outputId":"11a75eb4-45d5-404e-b78c-01392335eba9"},"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D,Convolution2D, MaxPooling2D, Flatten, Dense,Activation,BatchNormalization,Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import Model\n","from  tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import RMSprop\n","print(tf.__version__)\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","import json"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1nDaeKE_sf5","executionInfo":{"status":"ok","timestamp":1621100129737,"user_tz":-420,"elapsed":15545,"user":{"displayName":"tien dodinhtn123","photoUrl":"","userId":"17480689431746127203"}},"outputId":"178752df-05f2-42ee-a986-4ce8f6c5deb1"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-HCZsj-yjzc","executionInfo":{"status":"ok","timestamp":1621100134053,"user_tz":-420,"elapsed":2395,"user":{"displayName":"tien dodinhtn123","photoUrl":"","userId":"17480689431746127203"}},"outputId":"9c1317ca-a8b0-4b85-f5b8-f3cbc77464ec"},"source":["!ls \"/content/gdrive/My Drive/data\"\n","\n","train_generator = ImageDataGenerator(\n","    #rescale = 8/10,\n","    #fill_mode = 'nearest',\n","    fill_mode = \"constant\",\n","    #fill_mode = \"reflect\",\n","    #samplewise_center=True,\n","    #samplewise_std_normalization=True,\n","    #validation_split=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    vertical_flip=True,\n","    rotation_range=25,\n",")\n","\n","batch_size = 8\n","\n","train_gen = train_generator.flow_from_directory(\n","    \"/content/gdrive/My Drive/data\",\n","    #color_mode=\"grayscale\",\n","    target_size = (224,224),\n","    batch_size = batch_size, \n","    #class_mode='input',\n","    subset='training',\n","    shuffle=True\n",")\n","\n","\n","val_gen = train_generator.flow_from_directory(\"/content/gdrive/My Drive/data\",\n","    #color_mode=\"grayscale\",\n","    target_size = (224,224),\n","    batch_size = batch_size, \n","    #class_mode='input',\n","    subset='validation',\n","    shuffle=True\n",")\n","\n","\n","dict_ = val_gen.class_indices\n","class_dict = dict()\n","    \n","for key in dict_:\n","  class_dict[dict_[key]] = key\n","\n","with open(\"class.json\",\"w\") as f:\n","  json.dump(class_dict, f)\n","check_point = ModelCheckpoint(\"/content/gdrive/My Drive/face_detector.h5\"\n","                                ,monitor=\"loss\"\n","                                ,mode=\"min\"\n","                                ,save_best_only = True,\n","                                verbose=1)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["17103100361  17103100383  17103100397  17103100413  17103100428  17103100460\n","17103100364  17103100385  17103100398  17103100414  17103100432\n","17103100365  17103100389  17103100401  17103100418  17103100434\n","17103100368  17103100390  17103100404  17103100422  17103100444\n","17103100373  17103100394  17103100409  17103100427  17103100447\n","Found 345 images belonging to 26 classes.\n","Found 0 images belonging to 26 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TL1h3X-CB7gR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1621106106676,"user_tz":-420,"elapsed":2120362,"user":{"displayName":"tien dodinhtn123","photoUrl":"","userId":"17480689431746127203"}},"outputId":"16a53ea0-954c-4a05-c3a6-3bf8fcc7ecf9"},"source":["\n","\n","num_class = train_gen.num_classes\n","initial_model = tf.keras.applications.VGG16( weights='imagenet',\n","    include_top=False, input_tensor=None,\n","    input_shape=(224,224,3), pooling=None   \n",")\n","\n","\n","for layer in initial_model.layers:\n","    layer.trainable = False\n","last = initial_model.output\n","\n","last = Flatten()(last)\n","\n","last = Dense(4096, activation='relu')(last)\n","last = Dropout(0.25)(last)\n","last = Dense(4096, activation='relu')(last)\n","last = Dropout(0.25)(last)\n","last = BatchNormalization()(last)\n","#last = Dense(256, activation='relu')(last)\n","#last = Dense(158, activation='relu')(last)\n","last = Dense(num_class, activation='softmax')(last)\n","\n","model = Model(inputs = initial_model.input, outputs =last )\n","\n","print(model.summary())\n","#current_dir = os.path.dirname(os.path.realpath(__file__))\n","\n","\n","\"\"\"\n","val_generator = ImageDataGenerator(\n","    #rescale = 1./255,\n","    #fill_mode = 'nearest',\n","    fill_mode = \"constant\",\n","    validation_split=0.3,\n",")\n","\"\"\"\n","if(os.path.isfile(\"/content/gdrive/My Drive/face_detector_uneti.h5\")):\n","  model = load_model(\"/content/gdrive/My Drive/face_detector_uneti.h5\")\n","\n","\n","earlystop = EarlyStopping(\n","monitor='loss',\n","min_delta=0.4,\n","patience=10, \n","verbose=1,\n","restore_best_weights=True\n",")\n","\n","callbacks = [earlystop, check_point]\n","#callbacks = [check_point]\n","model.compile( loss = 'categorical_crossentropy',\n","              optimizer = \"nadam\",\n","              metrics = ['accuracy']\n",")\n","print(len(train_gen))\n","hist = model.fit(\n","    train_gen,\n","    #validation_data = val_gen,\n","    epochs = 150,\n","    callbacks = callbacks,\n","    \n",")\n","\n","model.save(\"/content/gdrive/My Drive/face_detector_uneti.h5\")\n","\n","\"\"\"\n","plt.plot(hist.history[\"accuracy\"])\n","plt.plot(hist.history['val_accuracy'])\n","plt.title(\"model accuracy\")\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n","plt.show()\n","\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title(\"model loss\")\n","plt.ylabel(\"Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"Loss\",\"Validation Loss\"])\n","plt.show()\n","\"\"\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4096)              102764544 \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 4096)              16384     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 26)                106522    \n","=================================================================\n","Total params: 134,383,450\n","Trainable params: 119,660,570\n","Non-trainable params: 14,722,880\n","_________________________________________________________________\n","None\n","44\n","Epoch 1/150\n","44/44 [==============================] - 187s 4s/step - loss: 0.1339 - accuracy: 0.9696\n","\n","Epoch 00001: loss did not improve from 0.13187\n","Epoch 2/150\n","44/44 [==============================] - 186s 4s/step - loss: 0.1233 - accuracy: 0.9607\n","\n","Epoch 00002: loss improved from 0.13187 to 0.13098, saving model to /content/gdrive/My Drive/face_detector.h5\n","Epoch 3/150\n","44/44 [==============================] - 194s 4s/step - loss: 0.3031 - accuracy: 0.9261\n","\n","Epoch 00003: loss did not improve from 0.13098\n","Epoch 4/150\n","44/44 [==============================] - 187s 4s/step - loss: 0.1203 - accuracy: 0.9671\n","\n","Epoch 00004: loss did not improve from 0.13098\n","Epoch 5/150\n","44/44 [==============================] - 186s 4s/step - loss: 0.1406 - accuracy: 0.9518\n","\n","Epoch 00005: loss did not improve from 0.13098\n","Epoch 6/150\n","44/44 [==============================] - 185s 4s/step - loss: 0.1151 - accuracy: 0.9595\n","\n","Epoch 00006: loss did not improve from 0.13098\n","Epoch 7/150\n","44/44 [==============================] - 185s 4s/step - loss: 0.2033 - accuracy: 0.9314\n","\n","Epoch 00007: loss did not improve from 0.13098\n","Epoch 8/150\n","44/44 [==============================] - 186s 4s/step - loss: 0.1766 - accuracy: 0.9640\n","\n","Epoch 00008: loss did not improve from 0.13098\n","Epoch 9/150\n","44/44 [==============================] - 187s 4s/step - loss: 0.1202 - accuracy: 0.9612\n","\n","Epoch 00009: loss did not improve from 0.13098\n","Epoch 10/150\n","44/44 [==============================] - 187s 4s/step - loss: 0.1872 - accuracy: 0.9516\n","\n","Epoch 00010: loss did not improve from 0.13098\n","Epoch 11/150\n","44/44 [==============================] - 187s 4s/step - loss: 0.1283 - accuracy: 0.9535\n","Restoring model weights from the end of the best epoch.\n","\n","Epoch 00011: loss improved from 0.13098 to 0.12019, saving model to /content/gdrive/My Drive/face_detector.h5\n","Epoch 00011: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nplt.plot(hist.history[\"accuracy\"])\\nplt.plot(hist.history[\\'val_accuracy\\'])\\nplt.title(\"model accuracy\")\\nplt.ylabel(\"Accuracy\")\\nplt.xlabel(\"Epoch\")\\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\\nplt.show()\\n\\nplt.plot(hist.history[\\'loss\\'])\\nplt.plot(hist.history[\\'val_loss\\'])\\nplt.title(\"model loss\")\\nplt.ylabel(\"Loss\")\\nplt.xlabel(\"Epoch\")\\nplt.legend([\"Loss\",\"Validation Loss\"])\\nplt.show()\\n'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"9joit6X4PO3F"},"source":[""],"execution_count":null,"outputs":[]}]}